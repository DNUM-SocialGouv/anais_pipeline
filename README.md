# anais_Nom_projet
Pipeline de l'√©tape de Nom_projet de la plateforme ANAIS ou en local

# Installation & Lancement du projet DBT

Cette section d√©crit les √©tapes n√©cessaires pour installer les d√©pendances, configurer DBT, instancier la base de donn√©es si besoin, et ex√©cuter le projet.

---

## 1. Installation des d√©pendances via UV

Le projet utilise [UV] pour la gestion des d√©pendances Python.  
Voici les √©tapes √† suivre pour initialiser l‚Äôenvironnement :

```bash

# 1. Se placer dans le dossier du projet
cd chemin/vers/le/projet

# 2. V√©rifier que uv est install√©
uv --version
pip install uv # Si pas install√©

# 3. Installer les d√©pendances
uv sync
```

---

## 2. ‚öôÔ∏è Configuration du fichier `profiles.yml`

DBT n√©cessite un fichier de configuration appel√© `profiles.yml`, qui contient les informations de connexion √† la base de donn√©es.

### O√π se trouve le fichier ?

Il doit se trouver dans le r√©pertoire suivant :
- **Linux/macOS** : `~/.dbt/profiles.yml`
- **Windows** : `C:\Users\<VotreNom>\.dbt\profiles.yml`

> Si le dossier `.dbt` n‚Äôexiste pas encore, vous pouvez le cr√©er manuellement.  

### O√π placer le fichier ?

Il doit √™tre plac√© dans √† la racine du projet Nom_projet (au m√™me niveau que le README et pyproject.toml) :
- **VM Cegedim** : `~/Nom_projet/profiles.yml`
- **Local** : `C:\Users\<VotreNom>\...\<projet>\profiles.yml`
 
Le fichier `profiles.yml` est disponible √† la racine du repo.  


### Que contient le fichier ?

Il contient les informations relatives aux bases de donn√©es des diff√©rents projets :
- Staging (DuckDB et postegres)
- Helios (DuckDB et postegres)
- Matrice (DuckDB et postegres)
- InspectionControlePA (DuckDB et postegres)
- CertDC (DuckDB et postegres)

Seul le password des bases postgres n'est pas indiqu√© -> il est indiqu√© dans le `.env`

---
## 3. ‚öôÔ∏è Configuration du fichier `metadata.yml`

Le fichier `metadata.yml` contient le param√©trage relatif aux fichiers en entr√©e et en sortie pour les diff√©rents projets.

Chaque projet √† sa section.

### Section directory

Contient les informations relatives aux fichiers et r√©pertoires du projet.
- local_directory_input = r√©pertoire o√π sont trouvables les fichiers csv en entr√©e. Exemple: "input/Nom_projet"
- local_directory_output = r√©pertoire o√π sont enregistr√©s les fichiers csv en sortie. Exemple: "output/Nom_projet"
- models_directory = r√©pertoire dans lequel sont enregistr√©s les mod√®les dbt du projet. dbt_Nom_projet" trouvable dans '/anais_Nom_projet/dbt_Nom_projet/models/'
- create_table_directory = r√©pertoire o√π sont enregistr√©s les fichiers SQL Create table. Exemple: 'output_sql/'
- remote_directory_input = listes des r√©pertoires sur le SFTP o√π sont enregistr√©s les fichiers csv en entr√©e (pour la recette). Exemple: "/SCN_BDD/Nom_projet/input"
- remote_directory_output = listes des r√©pertoires sur le SFTP o√π sont enregistr√©s les fichiers csv en sortie. Exemple: "/SCN_BDD/Nom_projet/output"


### Section **input_to_download**

Contient les informations relatives aux fichiers csv provenant du SFTP.
La section `input_to_download` (fichier √† r√©cup√©rer) contient :
- path = Chemin du fichier sur le SFTP. Exemple : "/SCN_BDD/INSERN"
- keyword = Terme dans le nom du fichier qui permet de le distinguer des autres fichiers. Exemple : "DNUM_TdB_CertDc" pour un fichier nommer DNUM_TdB_CertDcT42024T12025.csv
- file = Nom d'enregistrement du fichier une fois import√©. Exemple : "sa_insern.csv"

### Section **files_to_upload**

Contient les informations relatives aux vues √† exporter en csv.
La section `files_to_upload` √† envoyer contient :
- nom de la vue sql (nom du mod√®le dbt)
- radical du nom donn√© au fichier csv export√©. Le nom final sera '<radical>_<date_du_jour>.csv'. 
Exemple: ods_insee: ods_insee


---
## 4. Lancement du pipeline :

L'ensemble de la Pipeline est ex√©cut√© depuis le `main.py`.

### Pour l'ex√©cution de la pipeline:
1. Placer vous dans le bon r√©pertoire `anais_Nom_projet`

```bash
# Placer vous dans anais_Nom_projet
cd anais_Nom_projet
```

2. Lancer le `main.py`
```bash
uv run main.py --env "local" --profile "Nom_projet"
```
Avec env = 'local' ou 'anais' selon votre environnement de travail
et profile = 'Nom_projet'

### Pipeline sur env 'local':
1. R√©cup√©ration des fichiers d'input. !! Les fichiers doivent √™tre plac√©s manuellement dans le dossier `input/` sous format **.csv** !! (les d√©limiteurs sont g√©r√©s automatiquement)
2. Cr√©ation de la base DuckDB si inexistante.
3. Connexion √† la base DuckDB
4. Cr√©ation des tables si inexistantes
5. Lecture des csv avec standardisation des colonnes (sans caract√®res sp√©ciaux) -> injection des donn√©es dans les tables
6. V√©rification de l'injection
7. Ex√©cution de la commande `run dbt` -> Cr√©ation des vues relatives au projet
8. Export des vues dans le dossier `output/`
9. Fermeture de la connexion √† la base DuckDB

### Pipeline sur env 'anais':
1. R√©cup√©ration des fichiers d'input. Ces fichiers sont r√©cup√©r√©s automatiquement sur le SFTP et plac√©s dans le dossier `input/` sous format **.csv** (les d√©limiteurs sont g√©r√©s automatiquement)
2. Cr√©ation de la base Postgres si inexistante.
3. Connexion √† la base Postgres
4. Cr√©ation des tables si inexistantes
5. Lecture des csv avec standardisation des colonnes (sans caract√®res sp√©ciaux) -> injection des donn√©es dans les tables
6. V√©rification de l'injection
7. Ex√©cution de la commande `run dbt` -> Cr√©ation des vues relatives au projet
8. Export des vues dans le dossier `output/` au format **.csv**
9. Fermeture de la connexion √† la base Postgres
10. Export des **.csv** en output vers le SFTP


## 5. Architecture du projet
# MonProjet

## üèóÔ∏è Architecture du projet

```plaintext
.
‚îú‚îÄ‚îÄ data
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ duckdb_database.duckdb
‚îú‚îÄ‚îÄ input
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ cert_dc_insern_2023_2024.csv
‚îÇ   ...
‚îÇ   ‚îî‚îÄ‚îÄ v_region.csv
‚îú‚îÄ‚îÄ logs
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ sources.log
‚îú‚îÄ‚îÄ output
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ sa_ods_insee_2025_07_09.csv
‚îÇ   ...
‚îÇ   ‚îî‚îÄ‚îÄ sa_ods_pmsi_2025_07_09.csv
‚îú‚îÄ‚îÄ Staging
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ dbtStaging
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ dbt_project.yml
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ logs
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ macros
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ models
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ target
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ tests
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ logs
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ main.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ output_sql
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ cert_dc_insern_2023_2024.sql
‚îÇ¬†¬† ‚îÇ   ...
‚îÇ¬†¬† ‚îÇ   ‚îî‚îÄ‚îÄ v_region.sql
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pipeline
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.py
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ csv_management.py
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ database_pipeline.py
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ duckdb_pipeline.py
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ load_yml.py
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ metadata.yml
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ postgres_loader.py
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ sftp_sync.py
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ staging_tables.txt
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ staging_views.txt
‚îú‚îÄ‚îÄ poetry.lock
‚îú‚îÄ‚îÄ profiles.yml
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ uv.lock
```

## 6. Utilit√©s des fichiers
### ./dbtCertDC/
R√©pertoire de fonctionnement des mod√®les DBT -> cr√©ation de vue SQL.

dbt_project.yml : Fichier de configuration de DBT (obligatoire)

macros/ : R√©pertoire de stockage des macro jinja

models/ : R√©pertoire de stockage des mod√®les dbt

### ./pipeline/
R√©pertoire d'orchestration de la pipeline Python.

.env : Fichier secret contenant le param√©trage vers le SFTP et les mots de passes des bases de donn√©es postgres.

database_pipeline.py : R√©alise les actions communes pour n'importe quelle database (lecture de fichier SQL, ex√©cution du fichier sql, export de vues, run de la pipeline...). Fonctionne en compl√©ment avec duckdb_pipeline.py et postgres_loader.py.

duckdb_pipeline.py : R√©alise les actions sp√©cifiques √† une base (connexion √† la base, cr√©ation de table, chargement des donn√©es dans la BDD). Fonctionne en compl√©ment avec database_pipeline.py.

postgres_loader.py : R√©alise les actions sp√©cifiques √† une base postgres (connexion √† la base, cr√©ation de table, chargement des donn√©es dans la BDD). Fonctionne en compl√©ment avec database_pipeline.py.

sftp_sync.py : R√©alise les actions relatives √† une connexion SFTP (connexion, import, export...).

csv_management.py : R√©alise les actions relatives √† la manipulation de fichier csv (transformation d'un .xlsx en .csv, lecture du .csv avec d√©limiteur personnalis√©, standarisation des colonnes, conversion des types, export ...).

metadata.yml : Contient les informations relatives aux fichiers .csv provenant du SFTP.

load_yml.py : Lit un fichier .yml


./main.py : Programme d'ex√©cution de la pipeline


./output_sql/ : R√©pertoire qui contient les fichiers .sql de cr√©ation de table (CREATE TABLE)


./logs/ : R√©pertoire de la log


./data/duckdb_database.duckdb : Base duckDB


./input/ : R√©pertoire de stockage des fichiers .csv en entr√©e
./output/ : R√©pertoire de stockage des fichiers .csv en sortie


./profiles.yml : Contient les informations relatives aux bases des diff√©rents projets.


./poetry.lock
./uv.lock
./pyproject.toml